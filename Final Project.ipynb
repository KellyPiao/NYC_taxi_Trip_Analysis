{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8781fd1",
   "metadata": {},
   "source": [
    "### Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ac0be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetching complete.\n",
      "Processing 2009-01\n",
      "Processing 2009-02\n",
      "Processing 2009-03\n",
      "Processing 2009-04\n",
      "Processing 2009-05\n",
      "Processing 2009-06\n",
      "Processing 2009-07\n",
      "Processing 2009-08\n",
      "Processing 2009-09\n",
      "Processing 2009-10\n",
      "Processing 2009-11\n",
      "Processing 2009-12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import requests\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def fetch_yellow_taxi_links(base_url):\n",
    "    resp = requests.get(base_url)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    return soup.find_all('a', href=re.compile(r'^(?=.*yellow_tripdata)(?=.*(\\d{4}-\\d{2}\\.parquet|\\.zip)).*$'))\n",
    "\n",
    "\n",
    "def fetch_taxi_data(links, start_date, end_date): \n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for link in links:\n",
    "        url = link['href']\n",
    "        file_name = url.split('/')[-1]\n",
    "        date_str = file_name.split('_')[-1].split('.')[0]\n",
    "        date_obj = datetime.strptime(date_str, '%Y-%m')\n",
    "\n",
    "        if start_date <= date_obj <= end_date:\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                print(f'Downloading {file_name}...')\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "\n",
    "            if file_name.endswith('.zip'):\n",
    "                csv_file_name = file_name.replace('.zip', '.csv')\n",
    "                csv_file_path = os.path.join(output_dir, csv_file_name)\n",
    "\n",
    "                if not os.path.exists(csv_file_path):\n",
    "                    print(f'Extracting {file_name}...')\n",
    "                    with zipfile.ZipFile(file_path, 'r') as zip_file:\n",
    "                        zip_file.extractall(output_dir)\n",
    "\n",
    "                os.remove(file_path)\n",
    "\n",
    "    print('Data fetching complete.')\n",
    "\n",
    "\n",
    "def clean_and_sample_data(data: pd.DataFrame, columns_to_keep: list, columns_to_rename: dict,\n",
    "                          down_threshold: float, up_threshold: float,\n",
    "                          left_threshold: float, right_threshold: float, sample_size: int) -> pd.DataFrame:\n",
    "    data = data[columns_to_keep].copy()\n",
    "    data.rename(columns={old_name: new_name for old_name, new_name in zip(columns_to_keep, columns_to_rename)}, inplace=True)\n",
    "\n",
    "    data = data[(data['Start_Lat'] <= up_threshold) & (data['End_Lat'] <= up_threshold) & (data['Start_Lat'] >= down_threshold) & (\n",
    "        data['End_Lat'] >= down_threshold) & (data['Start_Lon'] <= right_threshold) & (data['End_Lon'] <= right_threshold) & (\n",
    "                data['Start_Lon'] >= left_threshold) & (data['End_Lon'] >= left_threshold)]\n",
    "\n",
    "    return data.sample(sample_size, random_state=42)\n",
    "\n",
    "def compile_and_clean_taxi_data() -> pd.DataFrame:\n",
    "    yellow_taxi_data = pd.DataFrame()\n",
    "\n",
    "    down_threshold = 40.560445\n",
    "    up_threshold = 40.908524\n",
    "    left_threshold = -74.242330\n",
    "    right_threshold = -73.717047\n",
    "    sample_size = 2500\n",
    "\n",
    "    for year in range(2009, 2010):\n",
    "#     for year in range(2009, 2016):\n",
    "        for month in range(1, 13):\n",
    "            print(f\"Processing {year}-{month:02d}\")   \n",
    "            if year == 2009:\n",
    "                columns_to_keep = ['Trip_Pickup_DateTime', 'Trip_Dropoff_DateTime', \"Trip_Distance\",\n",
    "                                   \"Start_Lon\", \"Start_Lat\", \"End_Lon\", \"End_Lat\", \"Fare_Amt\", \"Tip_Amt\"]\n",
    "                columns_to_rename = ['Pickup_Datetime', 'Dropoff_Datetime', \"Trip_Distance\",\n",
    "                                     \"Start_Lon\", \"Start_Lat\", \"End_Lon\", \"End_Lat\", \"Fare_Amt\", \"Tip_Amt\"]\n",
    "            elif year == 2010:\n",
    "                columns_to_keep = ['pickup_datetime', 'dropoff_datetime', \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\",\n",
    "                                   \"dropoff_longitude\", \"dropoff_latitude\", \"fare_amount\", \"tip_amount\"]\n",
    "                columns_to_rename = ['Pickup_Datetime', 'Dropoff_Datetime', \"Trip_Distance\",\n",
    "                                     \"Start_Lon\", \"Start_Lat\", \"End_Lon\", \"End_Lat\", \"Fare_Amt\", \"Tip_Amt\"]\n",
    "            else:  # year in [2011, 2012, 2013, 2014, 2015]\n",
    "                columns_to_keep = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\",\n",
    "                                   \"dropoff_longitude\", \"dropoff_latitude\", \"fare_amount\", \"tip_amount\"]\n",
    "                columns_to_rename = ['Pickup_Datetime', 'Dropoff_Datetime', \"Trip_Distance\",\n",
    "                                     \"Start_Lon\", \"Start_Lat\", \"End_Lon\", \"End_Lat\", \"Fare_Amt\", \"Tip_Amt\"]\n",
    "\n",
    "            data = pd.read_parquet(f\"{output_dir}/yellow_tripdata_{year}-{month:02d}.parquet\")\n",
    "            \n",
    "            sampled_data = clean_and_sample_data(data, columns_to_keep, columns_to_rename,\n",
    "                                                 down_threshold, up_threshold, left_threshold, right_threshold,\n",
    "                                                 sample_size)\n",
    "\n",
    "            yellow_taxi_data = yellow_taxi_data.append(sampled_data, ignore_index=True)\n",
    "\n",
    "    return yellow_taxi_data\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_url = 'https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page'\n",
    "    start_date = datetime(2009, 1, 1)\n",
    "    end_date = datetime(2015, 6, 30)\n",
    "    output_dir = 'monthly_data'\n",
    "\n",
    "    yellow_taxi_links = fetch_yellow_taxi_links(main_url)\n",
    "    fetch_taxi_data(yellow_taxi_links, start_date, end_date) \n",
    "     \n",
    "    compiled_taxi_data = compile_and_clean_taxi_data()\n",
    " \n",
    "    compiled_taxi_data.to_csv(\"cleaned_yellow_taxi_data_2009_2015.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b980f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff6979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed3225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e0f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74857d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d90935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250e4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46be18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b56bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df43b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a266603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d204ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48751835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb64b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6458504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1ef36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa66c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72614d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
